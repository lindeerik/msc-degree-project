{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Sci-kit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "#xg-boost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Random Forest Quantile\n",
    "from sklearn_quantile import RandomForestQuantileRegressor\n",
    "\n",
    "from visualization.visualize import *\n",
    "from data.data_loader import loadDataParquet\n",
    "from data.data_processing import processData, getDataProcessor, trainValTestSplit\n",
    "from models.training import trainModels\n",
    "from models.model import Model\n",
    "from models.conformalprediction.quantile_regression import *\n",
    "from models.conformalprediction.pinball import *\n",
    "from models.neuralnetwork.architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirParquet = \"../data/intermediate/\"\n",
    "df = loadDataParquet(dirParquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "230090"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DATA PREPARATION ###\n",
    "dependentCol = \"UL_bitrate\"\n",
    "\n",
    "selectedFloatCols = [\"Longitude\", \"Latitude\", \"Speed\", \"RSRP\",\"RSRQ\",\"SNR\"]\n",
    "selectedCatCols = [\"CellID\"]\n",
    "\n",
    "processor = getDataProcessor(selectedFloatCols, selectedCatCols, applyScaler=True)\n",
    "dataX, dataY = processData(df, selectedFloatCols, selectedCatCols, dependentCol, processor)\n",
    "dataX.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIVIDE INTO TRAINING, VALIDATION AND TEST ###\n",
    "trainRatio = 0.75\n",
    "validatioRatio = 0.15\n",
    "\n",
    "xTrain, xVal, xTest, yTrain, yVal, yTest = trainValTestSplit(dataX, dataY, trainRatio, validatioRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEURAL NET QUANTILE REGRESSOR ###\n",
    "alpha = 0.1\n",
    "lowerNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "upperNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(1-alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "regularNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(1-alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "paramGridNetLower = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "paramGridNetUpper = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "paramGridNetRegular = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "lowerScorer = pinballLossScorer(alpha/2)\n",
    "upperScorer = pinballLossScorer(1-alpha/2)\n",
    "lowerModel = Model(lowerNet, \"Lower Bound Neural Network\", paramGridNetLower, lowerScorer)\n",
    "upperModel = Model(upperNet, \"Upper Bound Neural Network\", paramGridNetUpper, upperScorer)\n",
    "\n",
    "quantileNeuralNetRegressor = QuantileRegressorNeuralNet([lowerModel, upperModel], alpha, \"Neural Network Quantile\")\n",
    "conformalQuantileNeuralNetRegressor = ConformalizedQuantileRegressor(quantileNeuralNetRegressor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RANDOM FOREST QUANTILE REGRESSOR ###\n",
    "alpha = 0.1\n",
    "# paramGridRfq = {\n",
    "#     # 'n_estimators': [50, 100, 200, 300],\n",
    "#     # 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "#     # 'max_depth': [None, 10, 20, 30, 40],\n",
    "#     # 'min_samples_split': [2, 5, 10, 20],\n",
    "#     # 'min_samples_leaf': [1, 2, 5, 10],\n",
    "#     # 'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "#     # 'max_features': ['sqrt', 'log2', None, 0.5, 1.0]\n",
    "#     # 'n_estimators': [100],\n",
    "#     # 'criterion': ['squared_error'],\n",
    "#     # 'max_depth': [None, 10, 20],\n",
    "#     # 'min_samples_split': [10],\n",
    "#     # 'min_samples_leaf': [10],\n",
    "#     # 'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "#     # 'max_features': ['sqrt', 'log2', None]\n",
    "#     'n_estimators': [100],\n",
    "#     'criterion': ['squared_error'],\n",
    "#     'max_depth': [10],\n",
    "#     'min_samples_split': [10],\n",
    "#     'min_samples_leaf': [10],\n",
    "#     'min_weight_fraction_leaf': [0.1],\n",
    "#     'max_features': ['log2']\n",
    "# }\n",
    "rfq = RandomForestQuantileRegressor(q = [alpha/2,1- alpha/2])\n",
    "paramGridRfq = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [10],\n",
    "    'min_samples_leaf': [10],\n",
    "    'min_weight_fraction_leaf': [0.1],\n",
    "    'max_features': ['log2']\n",
    "}\n",
    "doublePinballScorer = doublePinballLossScorer(alpha/2, 1-alpha/2)\n",
    "rqfModel = Model(rfq, \"Random Forest Quantile\", paramGridRfq, doublePinballScorer)\n",
    "\n",
    "quantileForestRegressor = QuantileRegressorRandomForest([rqfModel], alpha, \"Random Forest Quantile\")\n",
    "conformalQuantileForestRegressor = ConformalizedQuantileRegressor(quantileForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRAINING ###\n",
    "conformalQuantileRegressors = [conformalQuantileForestRegressor, conformalQuantileNeuralNetRegressor]\n",
    "for conformalModel in conformalQuantileRegressors:\n",
    "    conformalModel.fit(xTrain, yTrain, xVal, yVal, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Quantile coverage: 0.9300608166811468\n",
      "Conformalized Random Forest Quantile coverage: 0.9300608166811468\n",
      "Average Conformalized Random Forest Quantile width: 278.7750549316406\n",
      "Neural Network Quantile coverage: 0.891398783666377\n",
      "Conformalized Neural Network Quantile coverage: 0.9083405734144222\n",
      "Average Conformalized Neural Network Quantile width: 247.37098693847656\n"
     ]
    }
   ],
   "source": [
    "### EVALUATION ###\n",
    "for conformalModel in conformalQuantileRegressors:\n",
    "    print(f\"{conformalModel.getQuantileRegressor().getName()} coverage: {conformalModel.getQuantileRegressor().getCoverageRatio(xTest, yTest)}\")\n",
    "    print(f\"{conformalModel.getName()} coverage: {conformalModel.getCoverageRatio(xTest, yTest)}\")\n",
    "    print(f\"Average {conformalModel.getName()} width: {conformalModel.getAverageIntervalWidth(xTest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POINT ESTIMATION MODELS ###\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "paramGridRf = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "xGradBoost = xgb.XGBRegressor(random_state=42)\n",
    "paramGridXgb = {\n",
    "    'n_estimators': [200],\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [5],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0.1],\n",
    "    'reg_alpha': [0.01],\n",
    "    'reg_lambda': [1.5]\n",
    "}\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=nn.MSELoss,               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, external CV used\n",
    ")\n",
    "paramGridNet = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "\n",
    "models = [Model(rf, \"Random Forest\", paramGridRf), Model(xGradBoost, \"XGBoost\", paramGridXgb), Model(net, \"Neural Network\", paramGridNet)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best Parameters for Random Forest: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Training MSE: 3310.74\n",
      "Training R^2: 0.66\n",
      "Validation MSE: 6597.59\n",
      "Validation R^2: 0.31\n",
      "Test MSE: 6785.93\n",
      "Test R^2: 0.32\n",
      "\n",
      "Best Parameters for XGBoost: None\n",
      "Training MSE: 7142.90\n",
      "Training R^2: 0.27\n",
      "Validation MSE: 7748.77\n",
      "Validation R^2: 0.19\n",
      "Test MSE: 8020.17\n",
      "Test R^2: 0.20\n",
      "\n",
      "Best Parameters for Neural Network: None\n",
      "Training MSE: 7966.22\n",
      "Training R^2: 0.19\n",
      "Validation MSE: 8263.46\n",
      "Validation R^2: 0.14\n",
      "Test MSE: 8486.50\n",
      "Test R^2: 0.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = trainModels(models, xTrain, yTrain, xVal, yVal, xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest & Conformalized Random Forest Quantile - cover %: 0.9895742832319722\n",
      "Random Forest & Conformalized Neural Network Quantile - cover %: 0.9856646394439618\n",
      "XGBoost & Conformalized Random Forest Quantile - cover %: 1.0\n",
      "XGBoost & Conformalized Neural Network Quantile - cover %: 1.0\n",
      "Neural Network & Conformalized Random Forest Quantile - cover %: 0.998262380538662\n",
      "Neural Network & Conformalized Neural Network Quantile - cover %: 0.9978279756733276\n"
     ]
    }
   ],
   "source": [
    "### CHECK ALIGNMENT OF POINT ESTIMATES AND PREDICTION INTERVALS ###\n",
    "for model in models:\n",
    "    for conformalModel in conformalQuantileRegressors:\n",
    "        yPred = model.predict(xTest)\n",
    "        predIntervalCoverRatio = conformalModel.getCoverageRatio(xTest, yPred)\n",
    "        print(f\"{model.getName()} & {conformalModel.getName()} - cover %: {predIntervalCoverRatio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
