{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sci-kit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "#xg-boost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Random Forest Quantile\n",
    "from sklearn_quantile import RandomForestQuantileRegressor\n",
    "\n",
    "from visualization.visualize import *\n",
    "from data.data_loader import loadDataParquet\n",
    "from data.data_processing import processData, trainValTestSplit\n",
    "from models.training import trainModels\n",
    "from models.model import Model\n",
    "from models.conformalprediction.quantile_regression import *\n",
    "from models.conformalprediction.pinball import *\n",
    "from models.neuralnetwork.architecture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirParquet = \"../data/intermediate/\"\n",
    "df = loadDataParquet(dirParquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/category_encoders/ordinal.py:198: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X[column] = X[column].astype(\"object\").fillna(np.nan).map(col_mapping)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "230090"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### DATA PREPARATION ###\n",
    "dependentCol = \"UL_bitrate\"\n",
    "\n",
    "selectedFloatCols = [\"Longitude\", \"Latitude\", \"Speed\", \"RSRP\",\"RSRQ\",\"SNR\"]\n",
    "selectedCatCols = [\"CellID\"]\n",
    "\n",
    "dataX, dataY = processData(df, selectedFloatCols,selectedCatCols, dependentCol, True)\n",
    "dataX.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DIVIDE INTO TRAINING, VALIDATION AND TEST ###\n",
    "trainRatio = 0.75\n",
    "validatioRatio = 0.15\n",
    "\n",
    "xTrain, xVal, xTest, yTrain, yVal, yTest = trainValTestSplit(dataX, dataY, trainRatio, validatioRatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NEURAL NET QUANTILE REGRESSOR ###\n",
    "alpha = 0.1\n",
    "lowerNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "upperNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(1-alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "regularNet = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=PinballLoss(1-alpha/2),               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, we'll use external CV\n",
    ")\n",
    "paramGridNetLower = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "paramGridNetUpper = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "paramGridNetRegular = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "lowerScorer = pinballLossScorer(alpha/2)\n",
    "upperScorer = pinballLossScorer(1-alpha/2)\n",
    "lowerModel = Model(lowerNet, \"Lower Bound Neural Network\", paramGridNetLower, lowerScorer)\n",
    "upperModel = Model(upperNet, \"Upper Bound Neural Network\", paramGridNetUpper, upperScorer)\n",
    "\n",
    "quantileNeuralNetRegressor = QuantileRegressorNeuralNet([lowerModel, upperModel], alpha, \"Neural Network Quantile\")\n",
    "conformalQuantileNeuralNetRegressor = ConformalizedQuantileRegressor(quantileNeuralNetRegressor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RANDOM FOREST QUANTILE REGRESSOR ###\n",
    "alpha = 0.1\n",
    "# paramGridRfq = {\n",
    "#     # 'n_estimators': [50, 100, 200, 300],\n",
    "#     # 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n",
    "#     # 'max_depth': [None, 10, 20, 30, 40],\n",
    "#     # 'min_samples_split': [2, 5, 10, 20],\n",
    "#     # 'min_samples_leaf': [1, 2, 5, 10],\n",
    "#     # 'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "#     # 'max_features': ['sqrt', 'log2', None, 0.5, 1.0]\n",
    "#     # 'n_estimators': [100],\n",
    "#     # 'criterion': ['squared_error'],\n",
    "#     # 'max_depth': [None, 10, 20],\n",
    "#     # 'min_samples_split': [10],\n",
    "#     # 'min_samples_leaf': [10],\n",
    "#     # 'min_weight_fraction_leaf': [0.0, 0.1, 0.2],\n",
    "#     # 'max_features': ['sqrt', 'log2', None]\n",
    "#     'n_estimators': [100],\n",
    "#     'criterion': ['squared_error'],\n",
    "#     'max_depth': [10],\n",
    "#     'min_samples_split': [10],\n",
    "#     'min_samples_leaf': [10],\n",
    "#     'min_weight_fraction_leaf': [0.1],\n",
    "#     'max_features': ['log2']\n",
    "# }\n",
    "rfq = RandomForestQuantileRegressor(q = [alpha/2,1- alpha/2])\n",
    "paramGridRfq = {\n",
    "    'n_estimators': [100],\n",
    "    'criterion': ['squared_error'],\n",
    "    'max_depth': [10],\n",
    "    'min_samples_split': [10],\n",
    "    'min_samples_leaf': [10],\n",
    "    'min_weight_fraction_leaf': [0.1],\n",
    "    'max_features': ['log2']\n",
    "}\n",
    "doublePinballScorer = doublePinballLossScorer(alpha/2, 1-alpha/2)\n",
    "rqfModel = Model(rfq, \"Random Forest Quantile\", paramGridRfq, doublePinballScorer)\n",
    "\n",
    "quantileForestRegressor = QuantileRegressorRandomForest([rqfModel], alpha, \"Random Forest Quantile\")\n",
    "conformalQuantileForestRegressor = ConformalizedQuantileRegressor(quantileForestRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n"
     ]
    }
   ],
   "source": [
    "### TRAINING ###\n",
    "conformalQuantileRegressors = [conformalQuantileForestRegressor, conformalQuantileNeuralNetRegressor]\n",
    "for conformalModel in conformalQuantileRegressors:\n",
    "    conformalModel.fit(xTrain, yTrain, xVal, yVal, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Quantile coverage: 0.9200695047784535\n",
      "Conformalized Random Forest Quantile coverage: 0.9200695047784535\n",
      "Average Conformalized Random Forest Quantile width: 278.5295715332031\n",
      "Neural Network Quantile coverage: 0.9165942658557776\n",
      "Conformalized Neural Network Quantile coverage: 0.9131190269331017\n",
      "Average Conformalized Neural Network Quantile width: 272.803955078125\n"
     ]
    }
   ],
   "source": [
    "### EVALUATION ###\n",
    "for conformalModel in conformalQuantileRegressors:\n",
    "    print(f\"{conformalModel.getQuantileRegressor().getName()} coverage: {conformalModel.getQuantileRegressor().getCoverageRatio(xTest, yTest)}\")\n",
    "    print(f\"{conformalModel.getName()} coverage: {conformalModel.getCoverageRatio(xTest, yTest)}\")\n",
    "    print(f\"Average {conformalModel.getName()} width: {conformalModel.getAverageIntervalWidth(xTest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### POINT ESTIMATION MODELS ###\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "paramGridRf = {\n",
    "    'n_estimators': [300],\n",
    "    'max_depth': [20],\n",
    "    'min_samples_split': [5],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "xGradBoost = xgb.XGBRegressor(random_state=42)\n",
    "paramGridXgb = {\n",
    "    'n_estimators': [200],\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [5],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'gamma': [0.1],\n",
    "    'reg_alpha': [0.01],\n",
    "    'reg_lambda': [1.5]\n",
    "}\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    ThroughputPredictor,\n",
    "    module__input_size=dataX.shape[1],  # Pass the input size to the module\n",
    "    optimizer=optim.Adam,               # Optimizer\n",
    "    criterion=nn.MSELoss,               # Loss function\n",
    "    verbose=0,                          # Silence verbose output\n",
    "    train_split=None                    # Disable internal train/val split, external CV used\n",
    ")\n",
    "paramGridNet = {\n",
    "    'lr': [0.01],\n",
    "    'max_epochs': [100],\n",
    "    'optimizer__weight_decay': [0.01],\n",
    "    'batch_size': [128]\n",
    "}\n",
    "\n",
    "models = [Model(rf, \"Random Forest\", paramGridRf), Model(xGradBoost, \"XGBoost\", paramGridXgb), Model(net, \"Neural Network\", paramGridNet)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best Parameters for Random Forest: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Training MSE: 3278.11\n",
      "Training R^2: 0.67\n",
      "Validation MSE: 6702.58\n",
      "Validation R^2: 0.32\n",
      "Test MSE: 6922.27\n",
      "Test R^2: 0.30\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best Parameters for XGBoost: {'colsample_bytree': 0.8, 'gamma': 0.1, 'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 200, 'reg_alpha': 0.01, 'reg_lambda': 1.5, 'subsample': 0.8}\n",
      "Training MSE: 7131.48\n",
      "Training R^2: 0.27\n",
      "Validation MSE: 7916.50\n",
      "Validation R^2: 0.19\n",
      "Test MSE: 8097.69\n",
      "Test R^2: 0.18\n",
      "\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n",
      "/Users/eriklinde/Einride/msc-degree-project/.venv/lib/python3.9/site-packages/skorch/net.py:2231: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cuda_attrs = torch.load(f, **load_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Neural Network: {'batch_size': 128, 'lr': 0.01, 'max_epochs': 100, 'optimizer__weight_decay': 0.01}\n",
      "Training MSE: 7681.40\n",
      "Training R^2: 0.22\n",
      "Validation MSE: 8355.24\n",
      "Validation R^2: 0.15\n",
      "Test MSE: 8300.39\n",
      "Test R^2: 0.16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = trainModels(models, xTrain, yTrain, xVal, yVal, xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest & Conformalized Random Forest Quantile - cover %: 0.9917463075586447\n",
      "Random Forest & Conformalized Neural Network Quantile - cover %: 0.9917463075586447\n",
      "XGBoost & Conformalized Random Forest Quantile - cover %: 0.9978279756733276\n",
      "XGBoost & Conformalized Neural Network Quantile - cover %: 0.9991311902693311\n",
      "Neural Network & Conformalized Random Forest Quantile - cover %: 0.9969591659426585\n",
      "Neural Network & Conformalized Neural Network Quantile - cover %: 0.9995655951346655\n"
     ]
    }
   ],
   "source": [
    "### CHECK ALIGNMENT OF POINT ESTIMATES AND PREDICTION INTERVALS ###\n",
    "for model in models:\n",
    "    for conformalModel in conformalQuantileRegressors:\n",
    "        yPred = model.predict(xTest)\n",
    "        predIntervalCoverRatio = conformalModel.getCoverageRatio(xTest, yPred)\n",
    "        print(f\"{model.getName()} & {conformalModel.getName()} - cover %: {predIntervalCoverRatio}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
